{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(3)\n",
    "batch_size = 10000\n",
    "x = torch.rand(batch_size, 8, 1)\n",
    "w_base = torch.rand(1, 8, 16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     chosen \u001b[38;5;241m=\u001b[39m (y \u001b[38;5;241m==\u001b[39m inner)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y, chosen\n\u001b[0;32m----> 9\u001b[0m y_base, chosen_base \u001b[38;5;241m=\u001b[39m calc_chosen(\u001b[43mx\u001b[49m, w_base)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def calc_chosen(x, w):\n",
    "\n",
    "    inner = torch.min(x, w)\n",
    "    y = torch.max(inner, keepdim=True, dim=-2)[0]\n",
    "    chosen = (y == inner)\n",
    "    return y, chosen\n",
    "\n",
    "\n",
    "y_base, chosen_base = calc_chosen(x, w_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rel(x, t, chosen=None, dim=0):\n",
    "\n",
    "    negatives = torch.relu(x - t)\n",
    "    positives = torch.min(x, t)\n",
    "    if chosen is not None:\n",
    "        positives = chosen * positives\n",
    "\n",
    "    return (\n",
    "        positives.sum(dim=dim, keepdim=True) / \n",
    "        (positives.sum(dim=dim, keepdim=True) + negatives.sum(dim=dim, keepdim=True))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'update_rel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m chosen_rel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     w_rel \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_rel\u001b[49m(x, y_base, chosen_rel)\n\u001b[1;32m      6\u001b[0m     y_rel, chosen_rel \u001b[38;5;241m=\u001b[39m calc_chosen(x, w_rel)\n\u001b[1;32m      8\u001b[0m     true_count \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      9\u001b[0m         (chosen_rel \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m&\u001b[39m (chosen_base \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m     )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'update_rel' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# \n",
    "\n",
    "chosen_rel = None\n",
    "for i in range(5):\n",
    "    w_rel = update_rel(x, y_base, chosen_rel)\n",
    "    y_rel, chosen_rel = calc_chosen(x, w_rel)\n",
    "\n",
    "    true_count = (\n",
    "        (chosen_rel == True) & (chosen_base == True)\n",
    "    ).float()\n",
    "    fp_count = (\n",
    "        (chosen_rel == False) & (chosen_base == True)\n",
    "    ).float()\n",
    "    print(\n",
    "        'Rate: ',\n",
    "        true_count.sum() /\n",
    "        (fp_count + true_count).sum()\n",
    "    )\n",
    "    print(\n",
    "        'Loss: ', (y_rel - y_base).abs().mean()\n",
    "    )\n",
    "# for the first round i \n",
    "\n",
    "# increases to roughly 80% accuracy on the second iteration\n",
    "# indicates it should help to do an extra iteration\n",
    "\n",
    "# on the first round do not use chosen\n",
    "\n",
    "# inner_rel = torch.min(x, w_rel)\n",
    "# y_rel = inner_rel.max(dim=-2, keepdim=True)\n",
    "# chosen = (y_rel == inner_rel)\n",
    "\n",
    "# how many of the indices match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it is worth it to use rel..\n",
    "\n",
    "1. Don't know how much it will help in a realistic case but it looks quite promising here\n",
    "2. It's possible the straight through estimator is also doing as good as it can for multiple layers and that I need to add noise\n",
    "3. When there is not a clear optimum. Maybe it does not matter too much\n",
    "4. The loss decreases drastically on the second iteration. Regular gradient descent might get me the rest of the way\n",
    "5. Not sure how things will be affected by using both x_rel and w_rel. But doing just one seems to help dramatically\n",
    "\n",
    "\n",
    "For now... Implement a simpler version of the \"second order version\"\n",
    "\n",
    "\n",
    "a. Use rel loss 2\n",
    "b. gradually anneal it\n",
    "c. get rid of it\n",
    "\n",
    "d. How to deal with the regular intersection / Union?\n",
    " a. Use STE (?)\n",
    " b. Do not use it \n",
    " c. Use the \"soft version\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.003598089571570671\n",
      "1: 0.0019794574222539232\n",
      "2: 0.0017511042106094993\n",
      "3: 0.0016865623846673702\n",
      "4: 0.0016601198526759503\n",
      "5: 0.001626538789147346\n",
      "6: 0.0015927994214116207\n",
      "7: 0.001574100762947545\n",
      "8: 0.0015559627665678345\n",
      "9: 0.0015457969105837843\n",
      "10: 0.001954009567823591\n",
      "11: 0.0015383411576099034\n",
      "12: 0.0015190490285712707\n",
      "13: 0.0014959410557971347\n",
      "14: 0.001476551691966155\n",
      "15: 0.001453648162180487\n",
      "16: 0.001443045698636789\n",
      "17: 0.001414831922259889\n",
      "18: 0.00140547555358491\n",
      "19: 0.001388792095918067\n",
      "20: 0.001439365626112381\n",
      "21: 0.0012935908862000591\n",
      "22: 0.0012628046657206327\n",
      "23: 0.0012440436616940778\n",
      "24: 0.001227161038778958\n",
      "25: 0.0012112650769774483\n",
      "26: 0.001187106413189086\n",
      "27: 0.0011762844153998208\n",
      "28: 0.0011760871341640624\n",
      "29: 0.0011537875692784504\n",
      "30: 0.0011445264143374147\n",
      "31: 0.0010901195987398865\n",
      "32: 0.0010834471352068307\n",
      "33: 0.0010736261721393918\n",
      "34: 0.0010647626101522696\n",
      "35: 0.0010616460960959616\n",
      "36: 0.0010593236885269326\n",
      "37: 0.0010508778571339818\n",
      "38: 0.0010513670217905996\n",
      "39: 0.0010497733188757697\n",
      "40: 0.001038325635887258\n",
      "41: 0.0010254438016033154\n",
      "42: 0.0010188920482332947\n",
      "43: 0.0010143480244493466\n",
      "44: 0.001011607507567947\n",
      "45: 0.0010213486399336517\n",
      "46: 0.0010025852729707862\n",
      "47: 0.0010093212815862197\n",
      "48: 0.0010111738162857918\n",
      "49: 0.0010128778934514126\n",
      "50: 0.0010024461603452323\n",
      "51: 0.0009951890133839997\n",
      "52: 0.0009933189942819786\n",
      "53: 0.0009924181017883216\n",
      "54: 0.0009932555810878453\n",
      "55: 0.0009877595960610557\n",
      "56: 0.0009924903492844086\n",
      "57: 0.0009855897205622419\n",
      "58: 0.0009830753094976462\n",
      "59: 0.0009850091374585335\n",
      "60: 0.0009924604592821266\n",
      "61: 0.0009913774600688698\n",
      "62: 0.0009846438556508738\n",
      "63: 0.0009876526133275202\n",
      "64: 0.0009796132150848833\n",
      "65: 0.0009819849768559201\n",
      "66: 0.0009837888934225126\n",
      "67: 0.0009798525745650353\n",
      "68: 0.000979503499538508\n",
      "69: 0.000977964048374067\n",
      "70: 0.001000172702471808\n",
      "71: 0.0009918333800462416\n",
      "72: 0.0009923245886022437\n",
      "73: 0.0009857321340779337\n",
      "74: 0.000984337866082316\n",
      "75: 0.0009812227585883457\n",
      "76: 0.0009814815977411463\n",
      "77: 0.0009885839860049323\n",
      "78: 0.0009772858208139674\n",
      "79: 0.0009825403103604913\n",
      "80: 0.0009980755563400968\n",
      "81: 0.0009941171753055215\n",
      "82: 0.00098942787109438\n",
      "83: 0.000986206364417095\n",
      "84: 0.0009877370166462623\n",
      "85: 0.0009944066987372935\n",
      "86: 0.000984976820417833\n",
      "87: 0.000981658483086201\n",
      "88: 0.000983203459189191\n",
      "89: 0.0009852890138915163\n",
      "90: 0.0010024410741745577\n",
      "91: 0.0010044300992077192\n",
      "92: 0.0010035244764206059\n",
      "93: 0.0010037781859311876\n",
      "94: 0.000997743679835355\n",
      "95: 0.0009943555533603022\n",
      "96: 0.0010047719358537298\n",
      "97: 0.000991941316206527\n",
      "98: 0.000993847838879999\n",
      "99: 0.0009873416230577645\n",
      "100: 0.0010084007981622331\n",
      "101: 0.0010040094081277052\n",
      "102: 0.0010065043196258948\n",
      "103: 0.0010030064805516903\n",
      "104: 0.001006354695728308\n",
      "105: 0.0010108219730797447\n",
      "106: 0.0010101540821686953\n",
      "107: 0.0010045863742515727\n",
      "108: 0.0010121666518322935\n",
      "109: 0.0010000754455752859\n",
      "110: 0.0010182842327859489\n",
      "111: 0.0010125860402395925\n",
      "112: 0.0010185166589231998\n",
      "113: 0.0010286544101855046\n",
      "114: 0.0010130667927839994\n",
      "115: 0.0010144784508709195\n",
      "116: 0.0010192200970317272\n",
      "117: 0.001014027462334997\n",
      "118: 0.0010172474312985056\n",
      "119: 0.001020661824164747\n",
      "120: 0.0010282859490606698\n",
      "121: 0.00102820798542492\n",
      "122: 0.0010256443137326573\n",
      "123: 0.0010247201831197908\n",
      "124: 0.0010329213227687664\n",
      "125: 0.0010308260127571943\n",
      "126: 0.0010220401742071195\n",
      "127: 0.0010321719013449229\n",
      "128: 0.0010280217525926478\n",
      "129: 0.001021494971045965\n",
      "130: 0.0010389389876936433\n",
      "131: 0.0010497199969743437\n",
      "132: 0.0010369703795501514\n",
      "133: 0.0010358296950713178\n",
      "134: 0.0010414679668831958\n",
      "135: 0.0010364862185419548\n",
      "136: 0.001041613491929926\n",
      "137: 0.0010349194805102447\n",
      "138: 0.0010383395438341872\n",
      "139: 0.0010403311336884581\n",
      "140: 0.0010492696995622938\n",
      "141: 0.0010464679887459342\n",
      "142: 0.0010579108419722016\n",
      "143: 0.0010469928678549544\n",
      "144: 0.0010453279592874873\n",
      "145: 0.0010483133049587472\n",
      "146: 0.0010453912332253176\n",
      "147: 0.0010569261532878103\n",
      "148: 0.001049503334061113\n",
      "149: 0.001042164481227298\n",
      "150: 0.0012470640734286058\n",
      "151: 0.0011359469344709777\n",
      "152: 0.0011328844091253755\n",
      "153: 0.0011193462812542161\n",
      "154: 0.0011134719302217605\n",
      "155: 0.0011246986569294446\n",
      "156: 0.001111268978772237\n",
      "157: 0.0011087169825052252\n",
      "158: 0.0011096758395138704\n",
      "159: 0.0011075842945801118\n",
      "160: 0.0011089239409488119\n",
      "161: 0.0011063616721348577\n",
      "162: 0.0011074481579133226\n",
      "163: 0.00110482382647033\n",
      "164: 0.001100613416579281\n",
      "165: 0.001109512148519294\n",
      "166: 0.0011087708319596286\n",
      "167: 0.001105773751181845\n",
      "168: 0.0011050289723715638\n",
      "169: 0.0011077430195033644\n",
      "170: 0.0011075912389751006\n",
      "171: 0.0011054397600443586\n",
      "172: 0.0010974879473848623\n",
      "173: 0.0011047640346768725\n",
      "174: 0.0011057775604680087\n",
      "175: 0.001106067064006023\n",
      "176: 0.0010990955449841162\n",
      "177: 0.0010961909981774566\n",
      "178: 0.0011012211745557716\n",
      "179: 0.0011002560185940488\n",
      "180: 0.0011163179083326477\n",
      "181: 0.0011079229113846263\n",
      "182: 0.001104224963950677\n",
      "183: 0.001098966788164564\n",
      "184: 0.0010981114516388389\n",
      "185: 0.0011010127137650889\n",
      "186: 0.0010976283170011697\n",
      "187: 0.0010967828824090524\n",
      "188: 0.0010982838398894837\n",
      "189: 0.0011012991337706866\n",
      "190: 0.0010986726331713172\n",
      "191: 0.0010991117038728693\n",
      "192: 0.0011003347625071773\n",
      "193: 0.0010998726739913603\n",
      "194: 0.001105564361279005\n",
      "195: 0.0010926143761394145\n",
      "196: 0.0010913933017232184\n",
      "197: 0.0010953154621197831\n",
      "198: 0.0010994138171059327\n",
      "199: 0.001096443673949453\n"
     ]
    }
   ],
   "source": [
    "from rel import (\n",
    "    train, MinMax, MinMaxTPLearner, \n",
    "    MinMaxLoss, MinMaxLearner, TruncatedGaussianNoise, \n",
    "    MaxMinLearner, MaxMin, RandNoise, SmoothSTEMaxMin, SmoothSTEMinMax\n",
    ")\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import zenkai\n",
    "from itertools import chain\n",
    "\n",
    "torch.manual_seed(3)\n",
    "batch_size = 10000\n",
    "x = torch.rand(batch_size, 32)\n",
    "\n",
    "x_weight = 1.0\n",
    "w_weight = 0.01\n",
    "n_epochs = 200\n",
    "\n",
    "neuron_base = MaxMin(\n",
    "    32, 64\n",
    ")\n",
    "neuron_base2 = MinMax(\n",
    "    64, 64\n",
    ")\n",
    "\n",
    "# neuron1 = SmoothSTEMinMax(\n",
    "#     32, 64, a=10, adjust=False\n",
    "# )\n",
    "# neuron2 = SmoothSTEMinMax(\n",
    "#     64, 64, a=10, adjust=False\n",
    "# )\n",
    "# neuron1 = MinMaxTPLearner(\n",
    "#     32, 64, reduction='sum', rel_reduction='mean',\n",
    "#     x_weight=0.01, w_weight=0.01 #, a=5\n",
    "# )\n",
    "# neuron2 = MinMaxTPLearner(\n",
    "#     64, 64, reduction='sum', rel_reduction='mean', \n",
    "#     x_weight=0.01, w_weight=0.01 #, a=5\n",
    "# )\n",
    "\n",
    "neuron1 = MaxMinLearner(\n",
    "    32, 64, reduction='sum', rel_reduction='mean',\n",
    "    x_weight=0.01, w_weight=0.01\n",
    ")\n",
    "neuron2 = MinMaxLearner(\n",
    "    64, 64, reduction='sum', rel_reduction='mean', \n",
    "    x_weight=0.01, w_weight=0.01\n",
    ")\n",
    "\n",
    "# neuron1 = SmoothSTEMaxMin(\n",
    "#     32, 64, adjust=False, a=4\n",
    "# )\n",
    "# neuron2 = SmoothSTEMinMax(\n",
    "#     64, 64, adjust=False, a=4\n",
    "# )\n",
    "\n",
    "noiser = nn.Dropout(0.2)\n",
    "with torch.no_grad():\n",
    "    t = neuron_base2(neuron_base(x))\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(x, t)\n",
    "optim = torch.optim.Adam(chain(neuron1.parameters(), neuron2.parameters()), lr=1e-3)\n",
    "\n",
    "j = 0\n",
    "for i in range(n_epochs):\n",
    "    results = []\n",
    "    for x_i, t_i in torch.utils.data.DataLoader(\n",
    "        dataset, 128, True\n",
    "    ):\n",
    "        y_i = neuron1(x_i)\n",
    "        # y_i = torch.clamp(\n",
    "        #     y_i + torch.randn_like(y_i) * 0.01, 0, 1\n",
    "        # )\n",
    "        y_i = neuron2(y_i)\n",
    "        # loss = min_max_loss(x_i, y_i, t_i)\n",
    "        loss = (y_i - t_i).pow(2).mean()\n",
    "        # print(\n",
    "        #     loss.item(),\n",
    "        #     (y_i - t_i).pow(2).sum() / y_i.numel()\n",
    "        # )\n",
    "        optim.zero_grad()\n",
    "        # reg2 = 1e-6 * (1 - neuron2.weight).abs().mean()\n",
    "        # reg1 = 1e-6 * (neuron1.weight).abs().mean()\n",
    "        \n",
    "        reg2 = 1e-6 * (1 - neuron2.min_max.weight).abs().mean()\n",
    "        reg1 = 1e-6 * (neuron1.max_min.weight).abs().mean()\n",
    "        # (loss + reg2 + reg2).backward()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        zenkai.params.apply_p(\n",
    "            neuron1, lambda p: torch.clamp(p, 0.0, 1.0) \n",
    "        )\n",
    "        zenkai.params.apply_p(\n",
    "            neuron2, lambda p: torch.clamp(p, 0.0, 1.0) \n",
    "        )\n",
    "        results.append(loss.item())\n",
    "        # results.append(loss.item() / y_i.numel())\n",
    "    \n",
    "    # if i % 2 == 0:\n",
    "    j += 1\n",
    "    if (j >= 150):\n",
    "        neuron1.a = None\n",
    "        neuron2.a = None\n",
    "    elif (j % 10) == 0:\n",
    "        # neuron1.w_weight = 0.0 # neuron1.w_weight * 0.5\n",
    "        # neuron2.w_weight = 0.0 # neuron2.w_weight * 0.5\n",
    "        neuron1.a = neuron1.a + 2\n",
    "        neuron2.a = neuron2.a + 2\n",
    "    \n",
    "    # else:\n",
    "    #     neuron1.w_weight = 0.0 # neuron1.w_weight * 0.5\n",
    "    #     neuron2.w_weight = 0.01 # neuron2.w_weight * 0.5\n",
    "\n",
    "        # j = 0\n",
    "    \n",
    "    # neuron1.w_weight = neuron1.w_weight * 0.95\n",
    "    # neuron2.w_weight = neuron2.w_weight * 0.95\n",
    "    # neuron2.x_weight = neuron2.x_weight * 0.95\n",
    "    # neuron1.a = neuron1.a + 1\n",
    "    #neuron2.a = neuron2.a + 1\n",
    "    # else:\n",
    "    #     neuron1.w_weight = neuron1.w_weight * 0.95\n",
    "    #     neuron2.w_weight = 0.0\n",
    "    #     neuron2.x_weight = 0.1\n",
    "\n",
    "    print(f'{i}: {np.mean(results)}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
