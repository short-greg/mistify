{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(3)\n",
    "batch_size = 10000\n",
    "x = torch.rand(batch_size, 8, 1)\n",
    "w_base = torch.rand(1, 8, 16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     chosen \u001b[38;5;241m=\u001b[39m (y \u001b[38;5;241m==\u001b[39m inner)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y, chosen\n\u001b[0;32m----> 9\u001b[0m y_base, chosen_base \u001b[38;5;241m=\u001b[39m calc_chosen(\u001b[43mx\u001b[49m, w_base)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def calc_chosen(x, w):\n",
    "\n",
    "    inner = torch.min(x, w)\n",
    "    y = torch.max(inner, keepdim=True, dim=-2)[0]\n",
    "    chosen = (y == inner)\n",
    "    return y, chosen\n",
    "\n",
    "\n",
    "y_base, chosen_base = calc_chosen(x, w_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rel(x, t, chosen=None, dim=0):\n",
    "\n",
    "    negatives = torch.relu(x - t)\n",
    "    positives = torch.min(x, t)\n",
    "    if chosen is not None:\n",
    "        positives = chosen * positives\n",
    "\n",
    "    return (\n",
    "        positives.sum(dim=dim, keepdim=True) / \n",
    "        (positives.sum(dim=dim, keepdim=True) + negatives.sum(dim=dim, keepdim=True))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate:  tensor(0.4144)\n",
      "Loss:  tensor(0.1646)\n",
      "Rate:  tensor(0.8280)\n",
      "Loss:  tensor(0.0387)\n",
      "Rate:  tensor(0.8893)\n",
      "Loss:  tensor(0.0395)\n",
      "Rate:  tensor(0.8663)\n",
      "Loss:  tensor(0.0463)\n",
      "Rate:  tensor(0.8466)\n",
      "Loss:  tensor(0.0504)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# \n",
    "\n",
    "chosen_rel = None\n",
    "for i in range(5):\n",
    "    w_rel = update_rel(x, y_base, chosen_rel)\n",
    "    y_rel, chosen_rel = calc_chosen(x, w_rel)\n",
    "\n",
    "    true_count = (\n",
    "        (chosen_rel == True) & (chosen_base == True)\n",
    "    ).float()\n",
    "    fp_count = (\n",
    "        (chosen_rel == False) & (chosen_base == True)\n",
    "    ).float()\n",
    "    print(\n",
    "        'Rate: ',\n",
    "        true_count.sum() /\n",
    "        (fp_count + true_count).sum()\n",
    "    )\n",
    "    print(\n",
    "        'Loss: ', (y_rel - y_base).abs().mean()\n",
    "    )\n",
    "# for the first round i \n",
    "\n",
    "# increases to roughly 80% accuracy on the second iteration\n",
    "# indicates it should help to do an extra iteration\n",
    "\n",
    "# on the first round do not use chosen\n",
    "\n",
    "# inner_rel = torch.min(x, w_rel)\n",
    "# y_rel = inner_rel.max(dim=-2, keepdim=True)\n",
    "# chosen = (y_rel == inner_rel)\n",
    "\n",
    "# how many of the indices match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it is worth it to use rel..\n",
    "\n",
    "1. Don't know how much it will help in a realistic case but it looks quite promising here\n",
    "2. It's possible the straight through estimator is also doing as good as it can for multiple layers and that I need to add noise\n",
    "3. When there is not a clear optimum. Maybe it does not matter too much\n",
    "4. The loss decreases drastically on the second iteration. Regular gradient descent might get me the rest of the way\n",
    "5. Not sure how things will be affected by using both x_rel and w_rel. But doing just one seems to help dramatically\n",
    "\n",
    "\n",
    "For now... Implement a simpler version of the \"second order version\"\n",
    "\n",
    "\n",
    "a. Use rel loss 2\n",
    "b. gradually anneal it\n",
    "c. get rid of it\n",
    "\n",
    "d. How to deal with the regular intersection / Union?\n",
    " a. Use STE (?)\n",
    " b. Do not use it \n",
    " c. Use the \"soft version\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009311253794386416\n",
      "0.009936544737672503\n",
      "0.013782449302416814\n",
      "0.019162020598880097\n",
      "0.024298094189431095\n",
      "0.02743134305729896\n",
      "0.03035657768008075\n",
      "0.03272563341674926\n",
      "0.03546803260717211\n",
      "0.03723054567847071\n",
      "0.03830222078139269\n",
      "0.04047237855346897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# print(\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#     loss.item(),\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#     (y_i - t_i).pow(2).sum() / y_i.numel()\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     53\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 54\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     56\u001b[0m zenkai\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mapply_p(\n\u001b[1;32m     57\u001b[0m     neuron1, \u001b[38;5;28;01mlambda\u001b[39;00m p: torch\u001b[38;5;241m.\u001b[39mclamp(p, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m) \n\u001b[1;32m     58\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/autograd/function.py:253\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    252\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/zenkai/kaku/_lm2.py:497\u001b[0m, in \u001b[0;36mLearningF.backward\u001b[0;34m(ctx, *grad_outputs)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(x, t, state, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlmode \u001b[38;5;241m==\u001b[39m LMode\u001b[38;5;241m.\u001b[39mDefault:\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m     x_prime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_x(x, t, state, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlmode \u001b[38;5;241m==\u001b[39m LMode\u001b[38;5;241m.\u001b[39mStepPriority:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/zenkai/kaku/_lm2.py:359\u001b[0m, in \u001b[0;36mStepTheta._accumulate_hook_runner\u001b[0;34m(self, x, t, state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_accumulate_hook_runner\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: IO, t: IO, state: State, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call step wrapped with the hooks\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m        x (IO): the incoming IO\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m        t (IO): The target IO\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_accumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m posthook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulate_hooks:\n\u001b[1;32m    362\u001b[0m         posthook(\u001b[38;5;28mself\u001b[39m, x, t, state)\n",
      "File \u001b[0;32m~/Development/mistify/rel.py:396\u001b[0m, in \u001b[0;36mMinMaxLearner.accumulate\u001b[0;34m(self, x, t, state, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccumulate\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: zenkai\u001b[38;5;241m.\u001b[39mIO, t: zenkai\u001b[38;5;241m.\u001b[39mIO, state: zenkai\u001b[38;5;241m.\u001b[39mState, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    395\u001b[0m     t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(t\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 396\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_max_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    397\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Development/mistify/rel.py:234\u001b[0m, in \u001b[0;36mMinMaxLoss.forward\u001b[0;34m(self, x, y, t)\u001b[0m\n\u001b[1;32m    227\u001b[0m w_loss \u001b[38;5;241m=\u001b[39m zenkai\u001b[38;5;241m.\u001b[39mreduce(\n\u001b[1;32m    228\u001b[0m     ((inner_w \u001b[38;5;241m-\u001b[39m t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m chosen_w),\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel_reduction\n\u001b[1;32m    230\u001b[0m ) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_weight\n\u001b[1;32m    231\u001b[0m inner_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(\n\u001b[1;32m    232\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_max\u001b[38;5;241m.\u001b[39mweight[\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    233\u001b[0m )\n\u001b[0;32m--> 234\u001b[0m chosen_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_max_xrel2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m x_loss \u001b[38;5;241m=\u001b[39m zenkai\u001b[38;5;241m.\u001b[39mreduce(\n\u001b[1;32m    236\u001b[0m     ((inner_x \u001b[38;5;241m-\u001b[39m t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m chosen_x),\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel_reduction\n\u001b[1;32m    238\u001b[0m ) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_weight\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# print(base_loss.shape, w_loss.shape, x_loss.shape)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Development/mistify/rel.py:168\u001b[0m, in \u001b[0;36mMinMaxXRel2.forward\u001b[0;34m(self, w, t)\u001b[0m\n\u001b[1;32m    165\u001b[0m x_rel \u001b[38;5;241m=\u001b[39m min_max_rel(w, t, \u001b[38;5;28;01mNone\u001b[39;00m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    166\u001b[0m _, chosen_rel \u001b[38;5;241m=\u001b[39m min_max_chosen(x_rel, w)\n\u001b[0;32m--> 168\u001b[0m x_rel \u001b[38;5;241m=\u001b[39m \u001b[43mmin_max_rel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_rel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m _, chosen_rel \u001b[38;5;241m=\u001b[39m min_max_chosen(x_rel, w)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chosen_rel\n",
      "File \u001b[0;32m~/Development/mistify/rel.py:138\u001b[0m, in \u001b[0;36mmin_max_rel\u001b[0;34m(x, t, chosen, dim)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chosen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     positives \u001b[38;5;241m=\u001b[39m chosen \u001b[38;5;241m*\u001b[39m positives\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (\n\u001b[0;32m--> 138\u001b[0m     \u001b[43mpositives\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \n\u001b[1;32m    139\u001b[0m     (positives\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m negatives\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    140\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from rel import train, MinMax, MinMaxLoss, MinMaxLearner, TruncatedGaussianNoise, MaxMinLearner, MaxMin, RandNoise\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import zenkai\n",
    "\n",
    "torch.manual_seed(3)\n",
    "batch_size = 10000\n",
    "x = torch.rand(batch_size, 8)\n",
    "\n",
    "x_weight = 1.0\n",
    "w_weight = 0.01\n",
    "n_epochs = 400\n",
    "\n",
    "neuron_base = MinMax(\n",
    "    8, 16\n",
    ")\n",
    "neuron_base2 = MinMax(\n",
    "    16, 16\n",
    ")\n",
    "neuron1 = MinMaxLearner(\n",
    "    8, 16, reduction='mean', rel_reduction='mean', \n",
    "    x_weight=0.1, w_weight=0.01, a=8\n",
    ")\n",
    "neuron2 = MinMaxLearner(\n",
    "    16, 16, reduction='mean', rel_reduction='mean', \n",
    "    x_weight=0.01, w_weight=0.01, a=8\n",
    ")\n",
    "noiser = nn.Dropout(0.2)\n",
    "with torch.no_grad():\n",
    "    t = neuron_base2(neuron_base(x))\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    x, t\n",
    ")\n",
    "optim = torch.optim.Adam(neuron1.parameters(), lr=1e-3)\n",
    "\n",
    "j = 0\n",
    "for i in range(n_epochs):\n",
    "    results = []\n",
    "    for x_i, t_i in torch.utils.data.DataLoader(\n",
    "        dataset, 128, True\n",
    "    ):\n",
    "        y_i = neuron2(neuron1(x_i))\n",
    "        # loss = min_max_loss(x_i, y_i, t_i)\n",
    "\n",
    "        loss = (y_i - t_i).pow(2).sum()\n",
    "        # print(\n",
    "        #     loss.item(),\n",
    "        #     (y_i - t_i).pow(2).sum() / y_i.numel()\n",
    "        # )\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        zenkai.params.apply_p(\n",
    "            neuron1, lambda p: torch.clamp(p, 0.0, 1.0) \n",
    "        )\n",
    "        zenkai.params.apply_p(\n",
    "            neuron2, lambda p: torch.clamp(p, 0.0, 1.0) \n",
    "        )\n",
    "        # results.append(loss.item())\n",
    "        results.append(loss.item() / y_i.numel())\n",
    "    \n",
    "    # if i % 2 == 0:\n",
    "    # neuron1.w_weight = neuron1.w_weight * 0.95\n",
    "    # neuron2.w_weight = neuron2.w_weight * 0.95\n",
    "    # neuron2.x_weight = neuron2.x_weight * 0.95\n",
    "    # neuron1.a = neuron1.a + 1\n",
    "    #neuron2.a = neuron2.a + 1\n",
    "    # else:\n",
    "    #     neuron1.w_weight = neuron1.w_weight * 0.95\n",
    "    #     neuron2.w_weight = 0.0\n",
    "    #     neuron2.x_weight = 0.1\n",
    "\n",
    "    print(np.mean(results))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
