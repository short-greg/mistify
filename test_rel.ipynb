{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(3)\n",
    "batch_size = 10000\n",
    "x = torch.rand(batch_size, 8, 1)\n",
    "w_base = torch.rand(1, 8, 16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     chosen \u001b[38;5;241m=\u001b[39m (y \u001b[38;5;241m==\u001b[39m inner)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y, chosen\n\u001b[0;32m----> 9\u001b[0m y_base, chosen_base \u001b[38;5;241m=\u001b[39m calc_chosen(\u001b[43mx\u001b[49m, w_base)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def calc_chosen(x, w):\n",
    "\n",
    "    inner = torch.min(x, w)\n",
    "    y = torch.max(inner, keepdim=True, dim=-2)[0]\n",
    "    chosen = (y == inner)\n",
    "    return y, chosen\n",
    "\n",
    "\n",
    "y_base, chosen_base = calc_chosen(x, w_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rel(x, t, chosen=None, dim=0):\n",
    "\n",
    "    negatives = torch.relu(x - t)\n",
    "    positives = torch.min(x, t)\n",
    "    if chosen is not None:\n",
    "        positives = chosen * positives\n",
    "\n",
    "    return (\n",
    "        positives.sum(dim=dim, keepdim=True) / \n",
    "        (positives.sum(dim=dim, keepdim=True) + negatives.sum(dim=dim, keepdim=True))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'update_rel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m chosen_rel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     w_rel \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_rel\u001b[49m(x, y_base, chosen_rel)\n\u001b[1;32m      6\u001b[0m     y_rel, chosen_rel \u001b[38;5;241m=\u001b[39m calc_chosen(x, w_rel)\n\u001b[1;32m      8\u001b[0m     true_count \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      9\u001b[0m         (chosen_rel \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m&\u001b[39m (chosen_base \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m     )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'update_rel' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# \n",
    "\n",
    "chosen_rel = None\n",
    "for i in range(5):\n",
    "    w_rel = update_rel(x, y_base, chosen_rel)\n",
    "    y_rel, chosen_rel = calc_chosen(x, w_rel)\n",
    "\n",
    "    true_count = (\n",
    "        (chosen_rel == True) & (chosen_base == True)\n",
    "    ).float()\n",
    "    fp_count = (\n",
    "        (chosen_rel == False) & (chosen_base == True)\n",
    "    ).float()\n",
    "    print(\n",
    "        'Rate: ',\n",
    "        true_count.sum() /\n",
    "        (fp_count + true_count).sum()\n",
    "    )\n",
    "    print(\n",
    "        'Loss: ', (y_rel - y_base).abs().mean()\n",
    "    )\n",
    "# for the first round i \n",
    "\n",
    "# increases to roughly 80% accuracy on the second iteration\n",
    "# indicates it should help to do an extra iteration\n",
    "\n",
    "# on the first round do not use chosen\n",
    "\n",
    "# inner_rel = torch.min(x, w_rel)\n",
    "# y_rel = inner_rel.max(dim=-2, keepdim=True)\n",
    "# chosen = (y_rel == inner_rel)\n",
    "\n",
    "# how many of the indices match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it is worth it to use rel..\n",
    "\n",
    "1. Don't know how much it will help in a realistic case but it looks quite promising here\n",
    "2. It's possible the straight through estimator is also doing as good as it can for multiple layers and that I need to add noise\n",
    "3. When there is not a clear optimum. Maybe it does not matter too much\n",
    "4. The loss decreases drastically on the second iteration. Regular gradient descent might get me the rest of the way\n",
    "5. Not sure how things will be affected by using both x_rel and w_rel. But doing just one seems to help dramatically\n",
    "\n",
    "\n",
    "For now... Implement a simpler version of the \"second order version\"\n",
    "\n",
    "\n",
    "a. Use rel loss 2\n",
    "b. gradually anneal it\n",
    "c. get rid of it\n",
    "\n",
    "d. How to deal with the regular intersection / Union?\n",
    " a. Use STE (?)\n",
    " b. Do not use it \n",
    " c. Use the \"soft version\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.0016967366299226502\n",
      "1: 0.0014802171948919945\n",
      "2: 0.0014104823466932661\n",
      "3: 0.0013676510012673238\n",
      "4: 0.0013153605705386476\n",
      "5: 0.001288303830572463\n",
      "6: 0.0012621998719140133\n",
      "7: 0.0012498186662486647\n",
      "8: 0.0012388434401076711\n",
      "9: 0.0012366357333132927\n",
      "10: 0.001257302382477571\n",
      "11: 0.0010978669779893907\n",
      "12: 0.0010806813687262939\n",
      "13: 0.0010703679194815363\n",
      "14: 0.0010587150250160712\n",
      "15: 0.0010518502780012314\n",
      "16: 0.0010505045596156505\n",
      "17: 0.001044133163788179\n",
      "18: 0.0010577178216845836\n",
      "19: 0.0010375299482146584\n",
      "20: 0.0009959445709268315\n",
      "21: 0.0009460543507792622\n",
      "22: 0.0009361807974585909\n",
      "23: 0.0009301132957238845\n",
      "24: 0.0009164171627887725\n",
      "25: 0.0009098146442335712\n",
      "26: 0.0009069052271403466\n",
      "27: 0.0009061023725573964\n",
      "28: 0.0009066524651620678\n",
      "29: 0.0009025455138622488\n",
      "30: 0.0008959964741481162\n",
      "31: 0.0008853035912660387\n",
      "32: 0.0008770934382712917\n",
      "33: 0.0008776747537599995\n",
      "34: 0.0008812532502320842\n",
      "35: 0.0008679100458180131\n",
      "36: 0.0008741485513452016\n",
      "37: 0.0008666013106644814\n",
      "38: 0.0008716969375050615\n",
      "39: 0.000862150137678166\n",
      "40: 0.0008726880710300859\n",
      "41: 0.0008776827164206513\n",
      "42: 0.0008800564557785474\n",
      "43: 0.0008740619633971607\n",
      "44: 0.0008699015015736222\n",
      "45: 0.0008688401069810402\n",
      "46: 0.0008560539410402409\n",
      "47: 0.0008637481162772526\n",
      "48: 0.0008793003198431357\n",
      "49: 0.0008497962874030293\n",
      "50: 0.0008680316585681955\n",
      "51: 0.0008816043426329859\n",
      "52: 0.0008790303033458281\n",
      "53: 0.0008806310066528901\n",
      "54: 0.000873751618569316\n",
      "55: 0.0008793482505362717\n",
      "56: 0.0008648977444737065\n",
      "57: 0.000878458067515417\n",
      "58: 0.0008789675208574892\n",
      "59: 0.0008679071752224825\n",
      "60: 0.0009118305280498123\n",
      "61: 0.0009002769675365166\n",
      "62: 0.0008996438464927899\n",
      "63: 0.0009004906007041565\n",
      "64: 0.0009014304215972654\n",
      "65: 0.0008986884244729447\n",
      "66: 0.0009041566238149151\n",
      "67: 0.0008912997407237469\n",
      "68: 0.000886470528873556\n",
      "69: 0.0008881666161167093\n",
      "70: 0.0009386174290888955\n",
      "71: 0.0009395918496471795\n",
      "72: 0.0009417571790539955\n",
      "73: 0.0009347606661045759\n",
      "74: 0.0009267512536489794\n",
      "75: 0.0009445653516575223\n",
      "76: 0.0009397059123479773\n",
      "77: 0.0009289163900126668\n",
      "78: 0.0009321233042504025\n",
      "79: 0.000926291937733517\n",
      "80: 0.0009645497915629722\n",
      "81: 0.0009721107537787455\n",
      "82: 0.0009737715973884244\n",
      "83: 0.0009644938127397076\n",
      "84: 0.0009667977544809161\n",
      "85: 0.0009572083120163577\n",
      "86: 0.0009558711118430276\n",
      "87: 0.0009467088885581757\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m reg2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m neuron2\u001b[38;5;241m.\u001b[39mmin_max\u001b[38;5;241m.\u001b[39mweight)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     81\u001b[0m reg1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m \u001b[38;5;241m*\u001b[39m (neuron1\u001b[38;5;241m.\u001b[39mmax_min\u001b[38;5;241m.\u001b[39mweight)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 82\u001b[0m \u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreg2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreg2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     84\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/autograd/function.py:253\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    252\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/zenkai/kaku/_lm2.py:497\u001b[0m, in \u001b[0;36mLearningF.backward\u001b[0;34m(ctx, *grad_outputs)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(x, t, state, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlmode \u001b[38;5;241m==\u001b[39m LMode\u001b[38;5;241m.\u001b[39mDefault:\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m     x_prime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_x(x, t, state, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlmode \u001b[38;5;241m==\u001b[39m LMode\u001b[38;5;241m.\u001b[39mStepPriority:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/zenkai/kaku/_lm2.py:359\u001b[0m, in \u001b[0;36mStepTheta._accumulate_hook_runner\u001b[0;34m(self, x, t, state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_accumulate_hook_runner\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: IO, t: IO, state: State, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call step wrapped with the hooks\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m        x (IO): the incoming IO\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m        t (IO): The target IO\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_accumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m posthook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulate_hooks:\n\u001b[1;32m    362\u001b[0m         posthook(\u001b[38;5;28mself\u001b[39m, x, t, state)\n",
      "File \u001b[0;32m~/Development/mistify/rel.py:436\u001b[0m, in \u001b[0;36mMinMaxLearner.accumulate\u001b[0;34m(self, x, t, state, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccumulate\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: zenkai\u001b[38;5;241m.\u001b[39mIO, t: zenkai\u001b[38;5;241m.\u001b[39mIO, state: zenkai\u001b[38;5;241m.\u001b[39mState, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    435\u001b[0m     t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(t\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 436\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_max_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    437\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Development/mistify/rel.py:239\u001b[0m, in \u001b[0;36mMinMaxLoss.forward\u001b[0;34m(self, x, y, t)\u001b[0m\n\u001b[1;32m    234\u001b[0m chosen_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_max_wrel2(x, t)\n\u001b[1;32m    235\u001b[0m inner_w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(\n\u001b[1;32m    236\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mdetach(), \n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_max\u001b[38;5;241m.\u001b[39mweight[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    238\u001b[0m )\n\u001b[0;32m--> 239\u001b[0m w_loss \u001b[38;5;241m=\u001b[39m \u001b[43mzenkai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_w\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchosen_w\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_reduction\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_weight\n\u001b[1;32m    243\u001b[0m inner_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(\n\u001b[1;32m    244\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_max\u001b[38;5;241m.\u001b[39mweight[\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    245\u001b[0m )\n\u001b[1;32m    246\u001b[0m chosen_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_max_xrel2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_max\u001b[38;5;241m.\u001b[39mweight, t)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/zenkai/kaku/_assess.py:122\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(assessment, reduction, dim)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mreshape(loss\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39mkeepdim)\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be reduced.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\n\u001b[1;32m    123\u001b[0m     assessment: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    124\u001b[0m     reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    125\u001b[0m     dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Use to reduce a tensor given a specified reduction\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m        Assessment: An assessment reduced\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Reduction[reduction]\u001b[38;5;241m.\u001b[39mreduce(\n\u001b[1;32m    139\u001b[0m         assessment, dim\n\u001b[1;32m    140\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from rel import (\n",
    "    train, MinMax, MinMaxTPLearner, \n",
    "    MinMaxLoss, MinMaxLearner, TruncatedGaussianNoise, \n",
    "    MaxMinLearner, MaxMin, RandNoise, SmoothSTEMaxMin, SmoothSTEMinMax\n",
    ")\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import zenkai\n",
    "from itertools import chain\n",
    "\n",
    "torch.manual_seed(3)\n",
    "batch_size = 10000\n",
    "x = torch.rand(batch_size, 32)\n",
    "\n",
    "x_weight = 1.0\n",
    "w_weight = 0.01\n",
    "n_epochs = 200\n",
    "\n",
    "neuron_base = MaxMin(\n",
    "    32, 64\n",
    ")\n",
    "neuron_base2 = MinMax(\n",
    "    64, 64\n",
    ")\n",
    "\n",
    "# neuron1 = MinMax(\n",
    "#     8, 16\n",
    "# )\n",
    "# neuron2 = MinMax(\n",
    "#     16, 16\n",
    "# )\n",
    "neuron1 = MaxMinLearner(\n",
    "    32, 64, reduction='sum', rel_reduction='mean', \n",
    "    x_weight=0.01, w_weight=0.01, a=5\n",
    ")\n",
    "neuron2 = MinMaxLearner(\n",
    "    64, 64, reduction='mean', rel_reduction='mean', \n",
    "    x_weight=0.01, w_weight=0.01, a=5\n",
    ")\n",
    "\n",
    "# neuron1 = SmoothSTEMaxMin(\n",
    "#     32, 64, adjust=False, a=4\n",
    "# )\n",
    "# neuron2 = SmoothSTEMinMax(\n",
    "#     64, 64, adjust=False, a=4\n",
    "# )\n",
    "\n",
    "noiser = nn.Dropout(0.2)\n",
    "with torch.no_grad():\n",
    "    t = neuron_base2(neuron_base(x))\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    x, t\n",
    ")\n",
    "optim = torch.optim.Adam(chain(neuron1.parameters(), neuron2.parameters()), lr=1e-2)\n",
    "\n",
    "j = 0\n",
    "for i in range(n_epochs):\n",
    "    results = []\n",
    "    for x_i, t_i in torch.utils.data.DataLoader(\n",
    "        dataset, 128, True\n",
    "    ):\n",
    "        y_i = neuron1(x_i)\n",
    "        # y_i = torch.clamp(\n",
    "        #     y_i + torch.randn_like(y_i) * 0.01, 0, 1\n",
    "        # )\n",
    "        y_i = neuron2(y_i)\n",
    "        # loss = min_max_loss(x_i, y_i, t_i)\n",
    "        loss = (y_i - t_i).pow(2).sum()\n",
    "        # print(\n",
    "        #     loss.item(),\n",
    "        #     (y_i - t_i).pow(2).sum() / y_i.numel()\n",
    "        # )\n",
    "        optim.zero_grad()\n",
    "        # reg2 = 1e-6 * (1 - neuron2.weight).abs().mean()\n",
    "        # reg1 = 1e-6 * (neuron1.weight).abs().mean()\n",
    "        \n",
    "        reg2 = 1e-6 * (1 - neuron2.min_max.weight).abs().mean()\n",
    "        reg1 = 1e-6 * (neuron1.max_min.weight).abs().mean()\n",
    "        (loss + reg2 + reg2).backward()\n",
    "        # loss.backward()\n",
    "        optim.step()\n",
    "        zenkai.params.apply_p(\n",
    "            neuron1, lambda p: torch.clamp(p, 0.0, 1.0) \n",
    "        )\n",
    "        zenkai.params.apply_p(\n",
    "            neuron2, lambda p: torch.clamp(p, 0.0, 1.0) \n",
    "        )\n",
    "        # results.append(loss.item())\n",
    "        results.append(loss.item() / y_i.numel())\n",
    "    \n",
    "    # if i % 2 == 0:\n",
    "    j += 1\n",
    "    if (j >= 150):\n",
    "        neuron1.a = None\n",
    "        neuron2.a = None\n",
    "    elif (j % 10) == 0:\n",
    "        # neuron1.w_weight = 0.0 # neuron1.w_weight * 0.5\n",
    "        # neuron2.w_weight = 0.0 # neuron2.w_weight * 0.5\n",
    "        neuron1.a = neuron1.a + 2\n",
    "        neuron2.a = neuron2.a + 2\n",
    "    \n",
    "    # else:\n",
    "    #     neuron1.w_weight = 0.0 # neuron1.w_weight * 0.5\n",
    "    #     neuron2.w_weight = 0.01 # neuron2.w_weight * 0.5\n",
    "\n",
    "        # j = 0\n",
    "    \n",
    "    # neuron1.w_weight = neuron1.w_weight * 0.95\n",
    "    # neuron2.w_weight = neuron2.w_weight * 0.95\n",
    "    # neuron2.x_weight = neuron2.x_weight * 0.95\n",
    "    # neuron1.a = neuron1.a + 1\n",
    "    #neuron2.a = neuron2.a + 1\n",
    "    # else:\n",
    "    #     neuron1.w_weight = neuron1.w_weight * 0.95\n",
    "    #     neuron2.w_weight = 0.0\n",
    "    #     neuron2.x_weight = 0.1\n",
    "\n",
    "    print(f'{i}: {np.mean(results)}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
