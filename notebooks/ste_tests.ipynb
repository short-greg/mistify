{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import initialize\n",
    "from mistify import _functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to check if the straight through estimators succeed in optimizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optim_op(f, x1: torch.Tensor, t, n=400, **kwargs):\n",
    "    x1.requires_grad_()\n",
    "    optim = torch.optim.Adam([x1], lr=1e-2)\n",
    "    for i in range(n):\n",
    "        y = f(x1, **kwargs)\n",
    "        optim.zero_grad()\n",
    "        (y - t).pow(2).mean().backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7576, 0.4980, 0.9371, 0.7347],\n",
      "        [0.3138, 0.7999, 0.4162, 0.7544],\n",
      "        [0.5695, 0.5239, 0.7981, 0.7718],\n",
      "        [0.6826, 0.8100, 0.6397, 0.9743]], grad_fn=<MaximumBackward0>)\n",
      "tensor([[0.7576, 0.4980, 0.9371, 0.7347],\n",
      "        [0.3138, 0.7999, 0.4162, 0.7544],\n",
      "        [0.5695, 0.5239, 0.7981, 0.7718],\n",
      "        [0.6826, 0.8100, 0.6397, 0.9743]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test union\n",
    "torch.manual_seed(1)\n",
    "x1_b = torch.rand(4, 4)\n",
    "x2 = torch.rand(4, 4)\n",
    "t = F.union(x1_b, x2).detach()\n",
    "\n",
    "x1 = torch.rand(4, 4, requires_grad=True)\n",
    "optim_op(F.union, x1, t, n=800, x2=x2, g=F.ClipG(0.1))\n",
    "torch.sqrt((x1 - x1_b).pow(2).mean()).item()\n",
    "\n",
    "print(F.union(x1, x2)) \n",
    "print(F.union(x1_b, x2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5725, 0.2793, 0.4031, 0.6556],\n",
      "        [0.3138, 0.1980, 0.4162, 0.2843],\n",
      "        [0.3398, 0.4388, 0.7981, 0.5247],\n",
      "        [0.0112, 0.3051, 0.4635, 0.4550]], grad_fn=<MinimumBackward0>)\n",
      "tensor([[0.5725, 0.2793, 0.4031, 0.6556],\n",
      "        [0.0293, 0.1980, 0.3971, 0.2843],\n",
      "        [0.3398, 0.4388, 0.6387, 0.5247],\n",
      "        [0.0112, 0.3051, 0.4635, 0.4550]])\n"
     ]
    }
   ],
   "source": [
    "# Test union\n",
    "torch.manual_seed(1)\n",
    "x1_b = torch.rand(4, 4)\n",
    "x2 = torch.rand(4, 4)\n",
    "t = F.inter(x1_b, x2).detach()\n",
    "\n",
    "x1 = torch.rand(4, 4, requires_grad=True)\n",
    "optim_op(F.inter, x1, t, x2=x2, g=F.ClipG(0.1))\n",
    "torch.sqrt((x1 - x1_b).pow(2).mean()).item()\n",
    "\n",
    "\n",
    "print(F.inter(x1, x2)) \n",
    "print(F.inter(x1_b, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2793, 0.0293, 0.4388, 0.3051], grad_fn=<MinBackward0>)\n",
      "tensor([0.2793, 0.0293, 0.4388, 0.3051])\n"
     ]
    }
   ],
   "source": [
    "# Test inter on\n",
    "torch.manual_seed(1)\n",
    "x1_b = torch.rand(4, 4)\n",
    "# x2 = torch.rand(4, 4)\n",
    "t = F.inter_on(x1_b, -1, False).detach()\n",
    "\n",
    "x1 = torch.rand(4, 4, requires_grad=True)\n",
    "optim_op(F.inter_on, x1, t, dim=-1, keepdim=False)\n",
    "torch.sqrt((x1 - x1_b).pow(2).mean()).item()\n",
    "print(F.inter_on(x1, dim=-1)) \n",
    "print(F.inter_on(x1_b, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7576, 0.7999, 0.6387, 0.6826], grad_fn=<MaxBackward0>)\n",
      "tensor([0.7576, 0.7999, 0.6387, 0.6826])\n"
     ]
    }
   ],
   "source": [
    "# Test union on\n",
    "torch.manual_seed(1)\n",
    "x1_b = torch.rand(4, 4)\n",
    "# x2 = torch.rand(4, 4)\n",
    "t = F.union_on(x1_b, -1, False).detach()\n",
    "\n",
    "x1 = torch.rand(4, 4, requires_grad=True)\n",
    "optim_op(F.union_on, x1, t, dim=-1, keepdim=False, g=F.ClipG(0.1))\n",
    "torch.sqrt((x1 - x1_b).pow(2).mean()).item()\n",
    "\n",
    "\n",
    "print(F.union_on(x1, dim=-1)) \n",
    "print(F.union_on(x1_b, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1590016782283783\n",
      "tensor([[1., 0., 1., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 1., 1., 1.]], grad_fn=<BinaryGBackward>) tensor([[1., 0., 1., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Test binary\n",
    "torch.manual_seed(2)\n",
    "x1_b = torch.rand(4, 4)\n",
    "# x2 = torch.rand(4, 4)\n",
    "t = F.binarize(x1_b).detach()\n",
    "\n",
    "x1 = torch.rand(4, 4, requires_grad=True)\n",
    "optim_op(F.binarize, x1, t, n=1000, g=True, clip=0.1)\n",
    "print(torch.sqrt((x1 - x1_b).pow(2).mean()).item())\n",
    "print(F.binarize(x1), F.binarize(x1_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7361576557159424\n",
      "tensor([[-1.,  1., -1., -1.],\n",
      "        [-1.,  1., -1., -1.],\n",
      "        [-1.,  1., -1., -1.],\n",
      "        [ 1., -1., -1., -1.]], grad_fn=<SignGBackward>)\n",
      "tensor([[-1.,  1., -1., -1.],\n",
      "        [-1.,  1., -1., -1.],\n",
      "        [-1.,  1., -1., -1.],\n",
      "        [ 1., -1., -1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "# Test binary\n",
    "torch.manual_seed(2)\n",
    "x1_b = torch.randn(4, 4)\n",
    "# x2 = torch.rand(4, 4)\n",
    "t = F.signify(x1_b).detach()\n",
    "\n",
    "x1 = torch.rand(4, 4, requires_grad=True)\n",
    "optim_op(F.signify, x1, t, n=1000, g=True, clip=0.1)\n",
    "print(torch.sqrt((x1 - x1_b).pow(2).mean()).item())\n",
    "print(F.signify(x1)) \n",
    "print(F.signify(x1_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3310493528842926\n",
      "tensor([[0.8441, 0.1430, 0.9113, 0.4234],\n",
      "        [1.0000, 0.8571, 0.3276, 0.0000],\n",
      "        [0.8425, 0.0000, 0.6971, 0.5997],\n",
      "        [0.1702, 1.0000, 0.6001, 1.0000]], grad_fn=<ClampGBackward>)\n",
      "tensor([[0.8441, 0.1430, 0.9113, 0.4234],\n",
      "        [1.0000, 0.8571, 0.3276, 0.0000],\n",
      "        [0.8425, 0.0000, 0.6971, 0.5997],\n",
      "        [0.1702, 1.0000, 0.6001, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Test clamp\n",
    "torch.manual_seed(2)\n",
    "x1_b = torch.rand(4, 4) * 3 - 1\n",
    "# x2 = torch.rand(4, 4)\n",
    "t = F.clamp(x1_b).detach()\n",
    "\n",
    "x1 = torch.rand(4, 4, requires_grad=True)\n",
    "optim_op(F.clamp, x1, t, n=2000, g=True, clip=0.1)\n",
    "print(torch.sqrt((x1 - x1_b).pow(2).mean()).item())\n",
    "print(F.clamp(x1)) \n",
    "print(F.clamp(x1_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6533, 0.7580, 0.3844, 0.3148], grad_fn=<ClampGBackward>)\n",
      "tensor([0.6533, 0.7580, 0.3844, 0.3148])\n"
     ]
    }
   ],
   "source": [
    "# Test bounded union on\n",
    "torch.manual_seed(1)\n",
    "x1_b = torch.rand(4, 4) ** 4\n",
    "# x2 = torch.rand(4, 4)\n",
    "t = F.bounded_union_on(x1_b, -1, False).detach()\n",
    "\n",
    "x1 = torch.rand(4, 4, requires_grad=True)\n",
    "optim_op(F.bounded_union_on, x1, t, dim=-1, keepdim=False, g=True, clip=0.1)\n",
    "torch.sqrt((x1 - x1_b).pow(2).mean()).item()\n",
    "print(F.bounded_union_on(x1, dim=-1, keepdim=False)) \n",
    "print(F.bounded_union_on(x1_b, dim=-1, keepdim=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3826, 0.0852, 0.4276, 0.2986], grad_fn=<ReluBackward0>)\n",
      "tensor([0.3826, 0.0852, 0.4276, 0.2986])\n"
     ]
    }
   ],
   "source": [
    "# Test bounded inter on\n",
    "torch.manual_seed(1)\n",
    "x1_b = torch.rand(4, 4) ** 0.25\n",
    "# x2 = torch.rand(4, 4)\n",
    "t = F.bounded_inter_on(x1_b, -1, False).detach()\n",
    "\n",
    "x1 = torch.rand(4, 4, requires_grad=True)\n",
    "optim_op(F.bounded_inter_on, x1, t, dim=-1, keepdim=False, g=True, clip=0.1)\n",
    "torch.sqrt((x1 - x1_b).pow(2).mean()).item()\n",
    "print(F.bounded_inter_on(x1, dim=-1, keepdim=False)) \n",
    "print(F.bounded_inter_on(x1_b, dim=-1, keepdim=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9020, 0.5041, 0.9635, 0.9469],\n",
      "        [0.3138, 0.6073, 0.4411, 0.6082],\n",
      "        [0.4450, 0.5610, 0.9645, 0.8475],\n",
      "        [0.2283, 0.8186, 0.6859, 1.0000]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.9020, 0.5041, 0.9635, 0.9469],\n",
      "        [0.3138, 0.6073, 0.4411, 0.6082],\n",
      "        [0.4450, 0.5610, 0.9645, 0.8475],\n",
      "        [0.2283, 0.8186, 0.6859, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test bounded union\n",
    "torch.manual_seed(1)\n",
    "x1_b = torch.rand(4, 4) ** 4\n",
    "x2 = torch.rand(4, 4)\n",
    "t = F.bounded_union(x1_b, x2).detach()\n",
    "\n",
    "x1 = torch.rand(4, 4, requires_grad=True)\n",
    "optim_op(F.bounded_union, x1, t, x2=x2, g=True)\n",
    "torch.sqrt((x1 - x1_b).pow(2).mean()).item()\n",
    "print(F.bounded_union(x1, x2)) \n",
    "print(F.bounded_union(x1_b, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6270, 0.2342, 0.6029, 0.6668],\n",
      "        [0.0000, 0.3393, 0.2753, 0.4018],\n",
      "        [0.3376, 0.3862, 0.6925, 0.6028],\n",
      "        [0.0000, 0.4524, 0.4806, 0.6616]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.6270, 0.2342, 0.6029, 0.6668],\n",
      "        [0.0000, 0.3393, 0.2753, 0.4018],\n",
      "        [0.3376, 0.3862, 0.6925, 0.6028],\n",
      "        [0.0000, 0.4524, 0.4806, 0.6616]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test bounded inter\n",
    "torch.manual_seed(1)\n",
    "x1_b = torch.rand(4, 4) ** 0.5\n",
    "x2 = torch.rand(4, 4) ** 0.5\n",
    "t = F.bounded_inter(x1_b, x2).detach()\n",
    "\n",
    "x1 = torch.rand(4, 4, requires_grad=True)\n",
    "optim_op(F.bounded_inter, x1, t, x2=x2, g=True)\n",
    "torch.sqrt((x1 - x1_b).pow(2).mean()).item()\n",
    "print(F.bounded_inter(x1, x2)) \n",
    "print(F.bounded_inter(x1_b, x2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
