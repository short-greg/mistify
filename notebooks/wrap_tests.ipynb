{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import initialize\n",
    "from mistify import _functional as F\n",
    "import torch\n",
    "import typing\n",
    "import torch.nn as nn\n",
    "from torch.utils import data as torch_data\n",
    "from zenkai.utils import apply_to_parameters\n",
    "\n",
    "from mistify.learn import WrapNeuron, MaxMinRelOut\n",
    "from mistify import OrF, MulG\n",
    "from mistify.infer import Or, Inter, UnionOn\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_dataset1(shape, dropout_p: bool=0.5, exp: float=1.0, require_grad: bool=False):\n",
    "\n",
    "    data = torch.rand(*shape) ** exp\n",
    "    data = data * (torch.rand(shape) >= dropout_p)\n",
    "    if require_grad:\n",
    "        data.requires_grad_()\n",
    "        data.retain_grad()\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def epoch_str(epoch, n_epochs):\n",
    "    return f'Epoch {epoch + 1}/{n_epochs}'\n",
    "\n",
    "\n",
    "def optim(net: nn.Module, X: torch.Tensor, T: torch.Tensor, n_epochs: int=10, batch_size: int=128, epoch_callback=None):\n",
    "\n",
    "    dataset = torch_data.TensorDataset(X, T)\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "    with tqdm.tqdm(total=n_epochs) as pbar:\n",
    "        for _ in range(n_epochs):\n",
    "            epoch_loss = []\n",
    "\n",
    "            for x_i, t_i in torch_data.DataLoader(dataset, shuffle=True, batch_size=batch_size):\n",
    "                optim.zero_grad()\n",
    "                y_i = net(x_i)\n",
    "                loss = (y_i - t_i).pow(2).mean()\n",
    "                loss.backward()\n",
    "                # print('Grad: ', p[0].grad.abs().sum().item(), p[1].grad.abs().sum().item(), loss.item())\n",
    "                optim.step()\n",
    "                apply_to_parameters(\n",
    "                    net.parameters(), lambda x: torch.clamp(x, 0.0, 1.0)\n",
    "                )\n",
    "                epoch_loss.append(loss.item())\n",
    "            if epoch_callback is not None:\n",
    "                epoch_callback()\n",
    "            pbar.update(1)\n",
    "            # pbar.reset()\n",
    "            # pbar.set_description(epoch_str(0, n_epochs))\n",
    "            pbar.set_postfix({'loss': np.mean(epoch_loss)}, refresh=True)\n",
    "            # print(np.mean(epoch_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m T \u001b[38;5;241m=\u001b[39m base(X)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m      8\u001b[0m or_ \u001b[38;5;241m=\u001b[39m Or(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m8\u001b[39m, f\u001b[38;5;241m=\u001b[39mf)\n\u001b[0;32m---> 10\u001b[0m \u001b[43moptim\u001b[49m(or_, X, T, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     11\u001b[0m or_\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m OrF(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m optim(or_, X, T, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "f = WrapNeuron(OrF('std', 'std'), MaxMinRelOut())\n",
    "\n",
    "base = Or(16, 8)\n",
    "X = torch.rand(1000, 16)\n",
    "T = base(X).detach()\n",
    "\n",
    "\n",
    "or_ = Or(16, 8, f=f)\n",
    "\n",
    "optim(or_, X, T, n_epochs=1000)\n",
    "or_.f = OrF('std', 'std')\n",
    "optim(or_, X, T, n_epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 260/500 [00:23<00:22, 10.89it/s, loss=0.00135]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         net\u001b[38;5;241m.\u001b[39mf2\u001b[38;5;241m.\u001b[39mx_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     41\u001b[0m         net\u001b[38;5;241m.\u001b[39mf2\u001b[38;5;241m.\u001b[39mw_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 44\u001b[0m \u001b[43moptim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36moptim\u001b[0;34m(net, X, T, n_epochs, batch_size, epoch_callback)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m     12\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_i, t_i \u001b[38;5;129;01min\u001b[39;00m torch_data\u001b[38;5;241m.\u001b[39mDataLoader(dataset, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[1;32m     15\u001b[0m         optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m         y_i \u001b[38;5;241m=\u001b[39m net(x_i)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:163\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(elem, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# namedtuple\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[38;5;241m*\u001b[39m(default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)))\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequence\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# check to make sure that the elements in batch have consistent size\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(batch)\n\u001b[1;32m    166\u001b[0m     elem_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/abc.py:119\u001b[0m, in \u001b[0;36mABCMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, instance):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_abc_instancecheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/abc.py:123\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, subclass):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_abc_subclasscheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubclass\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/_collections_abc.py:317\u001b[0m, in \u001b[0;36mReversible.__subclasshook__\u001b[0;34m(cls, C)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__subclasshook__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, C):\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Reversible:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _check_methods(C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reversed__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(4)\n",
    "\n",
    "base = Or(16, 8)\n",
    "\n",
    "base = nn.Linear(16, 8)\n",
    "X = torch.rand(4000, 16)\n",
    "T = torch.sigmoid(base(X)).detach()\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.f1 = WrapNeuron(OrF('std', 'std'), MaxMinRelOut())\n",
    "        self.f2 = WrapNeuron(OrF('std', 'std'), MaxMinRelOut())\n",
    "        # self.f = OrF('std', 'std')\n",
    "        # self.f2 = WrapNeuron(OrF('std', 'std'), MaxMinRelOut())\n",
    "        self.or1 = Or(16, 16, f=self.f1)\n",
    "        self.or2 = Or(16, 8, f=self.f2) # OrF('std', 'std'))\n",
    "\n",
    "    # def set_f(self, f):\n",
    "    #     self.or1.f1 = f\n",
    "    #     self.or2.f = f\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.or2(self.or1(x))\n",
    "\n",
    "net = Net()\n",
    "\n",
    "weight1 = True\n",
    "net.f1.x_weight = 0.05\n",
    "net.f1.w_weight = 0.\n",
    "net.f2.x_weight = 0.0\n",
    "net.f2.w_weight = 0.05\n",
    "def callback():\n",
    "    if weight1:\n",
    "        net.f1.w_weight = 0.1 if weight1 is True else 0.0\n",
    "        net.f1.x_weight = 0.1 if weight1 is False else 0.0\n",
    "    else:\n",
    "        net.f2.x_weight = 0.1 if weight1 is True else 0.0\n",
    "        net.f2.w_weight = 0.1 if weight1 is False else 0.0\n",
    "\n",
    "\n",
    "optim(net, X, T, n_epochs=500, epoch_callback=callback)\n",
    "\n",
    "# net.set_f(OrF('std', 'std'))\n",
    "# # or_.f = \n",
    "# optim(net, X, T, n_epochs=500)\n",
    "# net.set_f(f)\n",
    "# optim(net, X, T, n_epochs=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 410/500 [00:53<00:11,  7.61it/s, loss=0.00272]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     net\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mx_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight_x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     40\u001b[0m     net\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mw_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight_x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 42\u001b[0m \u001b[43moptim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36moptim\u001b[0;34m(net, X, T, n_epochs, batch_size, epoch_callback)\u001b[0m\n\u001b[1;32m     16\u001b[0m y_i \u001b[38;5;241m=\u001b[39m net(x_i)\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m (y_i \u001b[38;5;241m-\u001b[39m t_i)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print('Grad: ', p[0].grad.abs().sum().item(), p[1].grad.abs().sum().item(), loss.item())\u001b[39;00m\n\u001b[1;32m     20\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310torch/lib/python3.10/site-packages/torch/autograd/function.py:253\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    252\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/mistify/mistify/_functional/_grad.py:314\u001b[0m, in \u001b[0;36mMinG.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;66;03m# condition2 = condition & (x2 > t)\u001b[39;00m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# condition2 = (x1 > x2) & (x1 > t)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# x1_grad[condition2] = torch.min(abs_grad, torch.relu(x1 - t))[condition2]\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     x1_grad \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mg(x1, x1_grad, condition)\n\u001b[0;32m--> 314\u001b[0m x1_grad \u001b[38;5;241m=\u001b[39m \u001b[43mreduce_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m x2_grad \u001b[38;5;241m=\u001b[39m grad_output\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    317\u001b[0m x2_grad[(x2 \u001b[38;5;241m>\u001b[39m x1)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/Development/mistify/mistify/utils/_utils.py:75\u001b[0m, in \u001b[0;36mreduce_as\u001b[0;34m(x, target)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (sz1, sz2) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(x\u001b[38;5;241m.\u001b[39msize(), target\u001b[38;5;241m.\u001b[39msize())):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sz1 \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sz2 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# test g\n",
    "torch.manual_seed(1)\n",
    "\n",
    "\n",
    "base = nn.Linear(16, 8)\n",
    "X = torch.rand(4000, 16)\n",
    "base = Or(16, 8, f=OrF('std', 'std'))\n",
    "T = base(X).detach()\n",
    "# T = torch.sigmoid(base(X)).detach()\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.f = WrapNeuron(OrF('std', 'std'), MaxMinRelOut())\n",
    "        # self.f = OrF('std', 'std')\n",
    "        # self.f2 = WrapNeuron(OrF('std', 'std'), MaxMinRelOut())\n",
    "        self.or1 = Or(16, 16, f=(\n",
    "            Inter(MulG(0.05)), UnionOn(MulG(0.1))\n",
    "        ))\n",
    "        self.or2 = Or(16, 8, f=(\n",
    "            Inter(MulG(0.05)), UnionOn(MulG(0.1))\n",
    "        )) # OrF('std', 'std'))\n",
    "\n",
    "    def set_f(self, f):\n",
    "        self.or1.f = f\n",
    "        self.or2.f = f\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.or2(self.or1(x))\n",
    "\n",
    "net = Net()\n",
    "\n",
    "weight_x = True\n",
    "# net.f.x_weight = 0.05\n",
    "# net.f.w_weight = 0.05\n",
    "def callback():\n",
    "    net.f.x_weight = 0.05 if weight_x is True else 0.0\n",
    "    net.f.w_weight = 0.05 if weight_x is False else 0.0\n",
    "\n",
    "optim(net, X, T, n_epochs=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
